{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PGmRwBRLt1Zv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/justin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/justin/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing packages for pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Packages for embeddings\n",
    "from gensim.models import KeyedVectors\n",
    "#Importing packages for cleaning the data\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Importing packages for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Importing packages for visualization of results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydksZwWAj9Kt",
    "outputId": "f77bda3a-b115-4407-e89a-a7e76f699cab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to dataset\n",
    "dataset_path = '/Users/unnimaya/Documents/Projectexperiments/AIRLINEDATASET/usairlinetweets.csv'\n",
    "\n",
    "# Load the dataset in the path using pandas\n",
    "df_airline = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the initial rows of the dataframe\n",
    "df_airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "B31SQQSikNuG",
    "outputId": "ccca8f18-918e-4fc2-c7e4-93b9131d1693"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_airline[[\"airline_sentiment\", \"text\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "GPT-iVxBksLb",
    "outputId": "0d4e7102-6664-47d4-d51f-59bb4d7f63be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()\n",
    "#imbalanced data set\n",
    "#can use resampling techniques like k fold cross validation for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data\n",
    "lemmatizer = WordNetLemmatizer()#Initialize lemmatizer\n",
    "stop_words = set(stopwords.words('english'))#Initialize stopwords\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = text.lower()#Converting the text to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)#Punctuation removal using regular expression\n",
    "    text = re.sub(r'\\d+', '', text)#Number removal\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]#Stop word removal and lemmatization\n",
    "    cleaned_text = ' '.join(tokens)#Joins the tokens to form cleaned sentence   \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST DATA CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuV1f6g2DOyQ",
    "outputId": "4057a000-8033-4709-aaef-0a8a7da900fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set class distribution:\n",
      " airline_sentiment\n",
      "negative    200\n",
      "neutral     200\n",
      "positive    200\n",
      "Name: count, dtype: int64\n",
      "Train set class distribution:\n",
      " airline_sentiment\n",
      "negative    8978\n",
      "neutral     2899\n",
      "positive    2163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The column 'airline_sentiment' is label\n",
    "class_label = 'airline_sentiment'\n",
    "\n",
    "# Sample 200 datapoints from each class for the test set\n",
    "test_df_class_1 = df[df[class_label] == 'negative'].sample(n=200, random_state=42)  # for class negative\n",
    "test_df_class_2 = df[df[class_label] == 'neutral'].sample(n=200, random_state=42)   # for class neutral\n",
    "test_df_class_3 = df[df[class_label] == 'positive'].sample(n=200, random_state=42)  # for class positive\n",
    "\n",
    "# Concatenate test_df_class_1, test_df_class_2 and test_df_class_3 to create the test set of 600 datapoints\n",
    "test_df = pd.concat([test_df_class_1, test_df_class_2, test_df_class_3])\n",
    "\n",
    "# original dataframe minus test_data = remaining data\n",
    "remaining_df = df.drop(test_df.index)\n",
    "\n",
    "# Display the number of samples in each class for both train and test sets\n",
    "# Check if the number of datapoints in remaining_df + test_df equals length of original dataframe\n",
    "print(\"Test set class distribution:\\n\", test_df[class_label].value_counts())\n",
    "print(\"Train set class distribution:\\n\", remaining_df[class_label].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FRjT5W4ScfI5"
   },
   "outputs": [],
   "source": [
    "# within test_df, \"text\" column is X and \"airline_sentiment\" column is Y\n",
    "# These will be referred to as X_test and y_test\n",
    "X_test= test_df[\"text\"]\n",
    "y_test= test_df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVpEjzFXQYk_",
    "outputId": "a2635892-a971-4e82-96f4-ce099fd06039"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 1151,  9111,  3326, 10891, 11322,  3709,  5261, 10060, 12446,  3089,\n",
       "       ...\n",
       "       11705, 13422,  2716,  3071, 13504,  4489,  8271, 11795,  7294,  8203],\n",
       "      dtype='int64', length=600)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTA1cJRcQfWC",
    "outputId": "b9fca4ad-27bb-4201-9f39-76453be9bcef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 1151,  9111,  3326, 10891, 11322,  3709,  5261, 10060, 12446,  3089,\n",
       "       ...\n",
       "       13324, 11935,  9346, 11781,  3022, 10759, 11149,  7523, 12754,   667],\n",
       "      dtype='int64', length=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_class_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2XoiZ5DQr7R",
    "outputId": "a89c28a2-2591-4395-f7f9-951de73216b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp5fluP-QuBr",
    "outputId": "4c48e3df-4d44-433f-a92e-0e1931841fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14040, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows of test_df and remaining_df when summed provides the number of rows of df\n",
    "remaining_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no oversampling or undersampling involved here, so train_df= remaining_df\n",
    "train_df= remaining_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When saving the weight, we are providing a prefix for the name, for ease of locating weights from this experiment\n",
    "weights_path_prefix = 'Word2vec_ORIGINAL_DATA_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jAKtnap6b2u"
   },
   "source": [
    "### LSTM WORD2VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINDATA TOKENIZATION AND PADDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6VEAyA-W8BMZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 310 ms, sys: 5.99 ms, total: 316 ms\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's create a tokenizer with 10000 words (all those words which do not come under this 10000, will be marked <OOV> )\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "# Train data preprocessing\n",
    "# Fitting the tokenizer on the traindata (only the text column)\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "# Data pre-processing\n",
    "max_length = 200  # Maximum sequence length= 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'  # padding ensures embeddings of shorter sentences have the same length as that of the longer ones\n",
    "X_train = tokenizer.texts_to_sequences(train_df['text'])  # using the tokenizer on train_df['text']\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding=padding_type, truncating=trunc_type)  # let's truncate and pad the tokens\n",
    "\n",
    "\n",
    "# Let's encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['airline_sentiment'])\n",
    "num_classes = len(label_encoder.classes_)   # number of classes\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)   # converting the labels to categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTDATA TOKENIZATION AND PADDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sQyqOj6E8Oey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.5 ms, sys: 3.95 ms, total: 27.5 ms\n",
      "Wall time: 24.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test data preprocessing\n",
    "# Performing the same steps of tokenizing,padding, and truncating on the test data too\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASS WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0.5212742258854979, 'neutral': 1.6143497757847534, 'positive': 2.163661581137309}\n",
      "{0: 0.5212742258854979, 1: 1.6143497757847534, 2: 2.163661581137309}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Find unique classes in train_df\n",
    "unique_classes = np.unique(train_df['airline_sentiment'])\n",
    "class_weights = {}\n",
    "# Calculate the weight for each class so that this weightage can be provided during training\n",
    "for cls in unique_classes:\n",
    "    class_weight = len(train_df['airline_sentiment']) / (len(unique_classes) * np.sum(train_df['airline_sentiment'] == cls))\n",
    "    class_weights[cls] = class_weight\n",
    "\n",
    "print(class_weights)\n",
    "# {0: 0.5212742258854979, 1: 1.6143497757847534, 2: 2.163661581137309} class weights are because they have unequal weightage since class sizes are different for all 3 labels\n",
    "class_numbers= [0, 1, 2]\n",
    "class_weights= dict(zip(class_numbers,list(class_weights.values()))) \n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORD2VEC EMBEDDINGS and MODEL CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_7WE8cn82Yd",
    "outputId": "f53bebf0-5ae0-4ff9-fdb6-6e0d2dc44251"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 1.09 s, total: 12.3 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load Word2Vec embeddings\n",
    "word2vec_path = '/Users/unnimaya/Documents/Projectexperiments/AIRLINEDATASET/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "embedding_dim = 300  # Since we loaded 300 dimensional Word2Vec mbeddings\n",
    "word_index = tokenizer.word_index  # Loading word index of Word2Vec embeddings\n",
    "num_words = min(10000, len(word_index) + 1)   # Number of words same as that of our tokenizer we defined above\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))    # Each word has 300D, so size of embedding matrix will be 10000x300\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < 10000:  # if i<10000, assign embedding vector to the word from Word2Vec\n",
    "        try:\n",
    "            embedding_vector = word2vec[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        except KeyError:\n",
    "            pass  # Word not found in Word2Vec, the embedding will be np.zeros((num_words, embedding_dim))\n",
    "            \n",
    "# Build Bidirectional LSTM model with pre-trained Word2Vec embeddings\n",
    "model = Sequential()\n",
    "# Create embedding for the input sequence using this first layer\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_length,\n",
    "                    weights=[embedding_matrix], trainable=False))\n",
    "# Using a series of Bidirectional LSTMs (with recurrent dropout) followed by dropout\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(128, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "# After the LSTM and dropout layers, we have two fully connected neural network layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # number of neurons in output layer= number of classes, activation function is softmax for multiclass classification problems\n",
    "\n",
    "# Using learning rate 0.01\n",
    "learning_rate = 0.001\n",
    "# Using Adam optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0) # using clipnorm to prevent exploding gradients if any\n",
    "\n",
    "# Compile the model with metric as accuracy and loss as categorical crossentropy (multiclass classification)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint callback- decides when to save weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath= weights_path_prefix+'_lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_{epoch:02d}.h5',  # Filepath format to include epoch number\n",
    "    save_weights_only=True,                         # Save only the model's weights\n",
    "    #save_freq=10 * (len(X_train) // 32),           # Save every 30 epochs (commented for now)\n",
    "    save_freq= 'epoch',                             # Save every epoch\n",
    "    verbose=1                                       # Print a message when saving the weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbqXpnTT882P",
    "outputId": "90bd905f-94fc-4439-c691-024839a4d2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.7554 - accuracy: 0.6958\n",
      "Epoch 1: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_01.h5\n",
      "439/439 [==============================] - 1409s 3s/step - loss: 0.7554 - accuracy: 0.6958 - val_loss: 0.5919 - val_accuracy: 0.7567\n",
      "Epoch 2/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7527\n",
      "Epoch 2: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_02.h5\n",
      "439/439 [==============================] - 1630s 4s/step - loss: 0.6352 - accuracy: 0.7527 - val_loss: 0.5944 - val_accuracy: 0.7850\n",
      "Epoch 3/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.5989 - accuracy: 0.7642\n",
      "Epoch 3: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_03.h5\n",
      "439/439 [==============================] - 1420s 3s/step - loss: 0.5989 - accuracy: 0.7642 - val_loss: 0.5565 - val_accuracy: 0.7767\n",
      "Epoch 4/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.7823\n",
      "Epoch 4: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_04.h5\n",
      "439/439 [==============================] - 1383s 3s/step - loss: 0.5633 - accuracy: 0.7823 - val_loss: 0.5631 - val_accuracy: 0.7717\n",
      "Epoch 5/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.7860\n",
      "Epoch 5: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_05.h5\n",
      "439/439 [==============================] - 1377s 3s/step - loss: 0.5498 - accuracy: 0.7860 - val_loss: 0.5374 - val_accuracy: 0.7833\n",
      "Epoch 6/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7952\n",
      "Epoch 6: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_06.h5\n",
      "439/439 [==============================] - 1431s 3s/step - loss: 0.5151 - accuracy: 0.7952 - val_loss: 0.5558 - val_accuracy: 0.7717\n",
      "Epoch 7/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7725\n",
      "Epoch 7: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_07.h5\n",
      "439/439 [==============================] - 1387s 3s/step - loss: 0.5586 - accuracy: 0.7725 - val_loss: 0.5172 - val_accuracy: 0.7833\n",
      "Epoch 8/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8127\n",
      "Epoch 8: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_08.h5\n",
      "439/439 [==============================] - 1400s 3s/step - loss: 0.4707 - accuracy: 0.8127 - val_loss: 0.5504 - val_accuracy: 0.7817\n",
      "Epoch 9/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8193\n",
      "Epoch 9: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_09.h5\n",
      "439/439 [==============================] - 1409s 3s/step - loss: 0.4469 - accuracy: 0.8193 - val_loss: 0.6010 - val_accuracy: 0.7817\n",
      "Epoch 10/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8353\n",
      "Epoch 10: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_10.h5\n",
      "439/439 [==============================] - 1408s 3s/step - loss: 0.4034 - accuracy: 0.8353 - val_loss: 0.5721 - val_accuracy: 0.7833\n",
      "Epoch 11/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8424\n",
      "Epoch 11: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_11.h5\n",
      "439/439 [==============================] - 1468s 3s/step - loss: 0.3777 - accuracy: 0.8424 - val_loss: 0.5689 - val_accuracy: 0.7917\n",
      "Epoch 12/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.8551\n",
      "Epoch 12: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_12.h5\n",
      "439/439 [==============================] - 1396s 3s/step - loss: 0.3480 - accuracy: 0.8551 - val_loss: 0.5550 - val_accuracy: 0.7967\n",
      "Epoch 13/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8674\n",
      "Epoch 13: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_13.h5\n",
      "439/439 [==============================] - 1406s 3s/step - loss: 0.3245 - accuracy: 0.8674 - val_loss: 0.6259 - val_accuracy: 0.7783\n",
      "Epoch 14/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8710\n",
      "Epoch 14: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_14.h5\n",
      "439/439 [==============================] - 1409s 3s/step - loss: 0.3047 - accuracy: 0.8710 - val_loss: 0.6821 - val_accuracy: 0.7783\n",
      "Epoch 15/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.8895\n",
      "Epoch 15: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_15.h5\n",
      "439/439 [==============================] - 1255s 3s/step - loss: 0.2624 - accuracy: 0.8895 - val_loss: 0.7605 - val_accuracy: 0.7767\n",
      "Epoch 16/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.8933\n",
      "Epoch 16: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_16.h5\n",
      "439/439 [==============================] - 1091s 2s/step - loss: 0.2520 - accuracy: 0.8933 - val_loss: 0.7509 - val_accuracy: 0.7800\n",
      "Epoch 17/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9046\n",
      "Epoch 17: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_17.h5\n",
      "439/439 [==============================] - 1072s 2s/step - loss: 0.2236 - accuracy: 0.9046 - val_loss: 0.8290 - val_accuracy: 0.7783\n",
      "Epoch 18/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9162\n",
      "Epoch 18: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_18.h5\n",
      "439/439 [==============================] - 1018s 2s/step - loss: 0.2080 - accuracy: 0.9162 - val_loss: 0.7682 - val_accuracy: 0.7750\n",
      "Epoch 19/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9172\n",
      "Epoch 19: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_19.h5\n",
      "439/439 [==============================] - 939s 2s/step - loss: 0.1963 - accuracy: 0.9172 - val_loss: 0.8295 - val_accuracy: 0.7600\n",
      "Epoch 20/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9281\n",
      "Epoch 20: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_20.h5\n",
      "439/439 [==============================] - 912s 2s/step - loss: 0.1718 - accuracy: 0.9281 - val_loss: 0.9483 - val_accuracy: 0.7800\n",
      "Epoch 21/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9316\n",
      "Epoch 21: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_21.h5\n",
      "439/439 [==============================] - 932s 2s/step - loss: 0.1672 - accuracy: 0.9316 - val_loss: 0.7646 - val_accuracy: 0.7783\n",
      "Epoch 22/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9428\n",
      "Epoch 22: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_22.h5\n",
      "439/439 [==============================] - 923s 2s/step - loss: 0.1504 - accuracy: 0.9428 - val_loss: 0.9800 - val_accuracy: 0.7883\n",
      "Epoch 23/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9447\n",
      "Epoch 23: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_23.h5\n",
      "439/439 [==============================] - 939s 2s/step - loss: 0.1392 - accuracy: 0.9447 - val_loss: 1.0263 - val_accuracy: 0.7717\n",
      "Epoch 24/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9508\n",
      "Epoch 24: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_24.h5\n",
      "439/439 [==============================] - 926s 2s/step - loss: 0.1287 - accuracy: 0.9508 - val_loss: 0.8199 - val_accuracy: 0.7883\n",
      "Epoch 25/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9549\n",
      "Epoch 25: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_25.h5\n",
      "439/439 [==============================] - 906s 2s/step - loss: 0.1230 - accuracy: 0.9549 - val_loss: 1.0836 - val_accuracy: 0.7683\n",
      "Epoch 26/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9564\n",
      "Epoch 26: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_26.h5\n",
      "439/439 [==============================] - 1029s 2s/step - loss: 0.1225 - accuracy: 0.9564 - val_loss: 1.0198 - val_accuracy: 0.7750\n",
      "Epoch 27/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9600\n",
      "Epoch 27: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_27.h5\n",
      "439/439 [==============================] - 1105s 3s/step - loss: 0.1080 - accuracy: 0.9600 - val_loss: 0.9038 - val_accuracy: 0.7783\n",
      "Epoch 28/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9637\n",
      "Epoch 28: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_28.h5\n",
      "439/439 [==============================] - 1041s 2s/step - loss: 0.1005 - accuracy: 0.9637 - val_loss: 1.0086 - val_accuracy: 0.7800\n",
      "Epoch 29/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9660\n",
      "Epoch 29: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_29.h5\n",
      "439/439 [==============================] - 1043s 2s/step - loss: 0.0945 - accuracy: 0.9660 - val_loss: 1.1393 - val_accuracy: 0.7833\n",
      "Epoch 30/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9677\n",
      "Epoch 30: saving model to Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_30.h5\n",
      "439/439 [==============================] - 1066s 2s/step - loss: 0.0960 - accuracy: 0.9677 - val_loss: 1.1221 - val_accuracy: 0.7633\n",
      "CPU times: user 10h 46min 59s, sys: 4h 24min 46s, total: 15h 11min 46s\n",
      "Wall time: 10h 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRAINING THE MODEL\n",
    "# We supply test data as validation data to observe the model performance after each epoch\n",
    "# 30 iterations (epochs)\n",
    "# Uses class weight balancing based on class imbalance in data (no class imbalance here for oversampling)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=32, callbacks=[checkpoint], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# load and compile a saved weight\n",
    "model.load_weights('Word2vec_ORIGINAL_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_12.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wmYpAQLx9FJt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 279ms/step - loss: 0.5550 - accuracy: 0.7967\n",
      "Test Accuracy: 0.79666668176651\n",
      "CPU times: user 9.63 s, sys: 3.37 s, total: 13 s\n",
      "Wall time: 6.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the loaded weights and evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 279ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming X_test is your test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Get the predicted class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Precision = 0.8163, Recall = 0.8000\n",
      "Class 1: Precision = 0.7462, Recall = 0.7350\n",
      "Class 2: Precision = 0.8261, Recall = 0.8550\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming conf_matrix is the confusion matrix\n",
    "TP = np.diag(conf_matrix)\n",
    "FP = np.sum(conf_matrix, axis=0) - TP\n",
    "FN = np.sum(conf_matrix, axis=1) - TP\n",
    "\n",
    "# Avoid division by zero\n",
    "precision = np.divide(TP, (TP + FP), where=(TP + FP) != 0)\n",
    "recall = np.divide(TP, (TP + FN), where=(TP + FN) != 0)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
