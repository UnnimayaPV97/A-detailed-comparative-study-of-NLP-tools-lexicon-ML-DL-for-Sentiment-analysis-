{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giMi-c-3QC2R"
   },
   "source": [
    "**Loading the required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGmRwBRLt1Zv",
    "outputId": "d0b309b8-615c-4d21-b5c8-1e1550f64a9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/justin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/justin/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing packages for pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Packages for embeddings\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Importing packages for cleaning the data\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Importing packages for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Importing packages for visualization of results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZyqmoNAQC2V"
   },
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydksZwWAj9Kt",
    "outputId": "f77bda3a-b115-4407-e89a-a7e76f699cab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to dataset\n",
    "dataset_path = '/Users/unnimaya/Documents/Projectexperiments/AIRLINEDATASET/usairlinetweets.csv'\n",
    "\n",
    "# Load the dataset in the path using pandas\n",
    "df_airline = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the initial rows of the dataframe\n",
    "df_airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "B31SQQSikNuG",
    "outputId": "ccca8f18-918e-4fc2-c7e4-93b9131d1693"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_airline[[\"airline_sentiment\", \"text\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "GPT-iVxBksLb",
    "outputId": "0d4e7102-6664-47d4-d51f-59bb4d7f63be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()\n",
    "#imbalanced data set\n",
    "#can use resampling techniques like k fold cross validation for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data\n",
    "lemmatizer = WordNetLemmatizer()#Initialize lemmatizer\n",
    "stop_words = set(stopwords.words('english'))#Initialize stopwords\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = text.lower()#Converting the text to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)#Punctuation removal using regular expression\n",
    "    text = re.sub(r'\\d+', '', text)#Number removal\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]#Stop word removal and lemmatization\n",
    "    cleaned_text = ' '.join(tokens)#Joins the tokens to form cleaned sentence   \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6VArjjqQC2W"
   },
   "source": [
    "**TEST DATA CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuV1f6g2DOyQ",
    "outputId": "4057a000-8033-4709-aaef-0a8a7da900fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set class distribution:\n",
      " airline_sentiment\n",
      "negative    200\n",
      "neutral     200\n",
      "positive    200\n",
      "Name: count, dtype: int64\n",
      "Train set class distribution:\n",
      " airline_sentiment\n",
      "negative    8978\n",
      "neutral     2899\n",
      "positive    2163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The column 'airline_sentiment' is label\n",
    "class_label = 'airline_sentiment'\n",
    "\n",
    "# Sample 200 datapoints from each class for the test set\n",
    "test_df_class_1 = df[df[class_label] == 'negative'].sample(n=200, random_state=42)  # for class negative\n",
    "test_df_class_2 = df[df[class_label] == 'neutral'].sample(n=200, random_state=42)   # for class neutral\n",
    "test_df_class_3 = df[df[class_label] == 'positive'].sample(n=200, random_state=42)  # for class positive\n",
    "\n",
    "# Concatenate test_df_class_1, test_df_class_2 and test_df_class_3 to create the test set of 600 datapoints\n",
    "test_df = pd.concat([test_df_class_1, test_df_class_2, test_df_class_3])\n",
    "\n",
    "# original dataframe minus test_data = remaining data\n",
    "remaining_df = df.drop(test_df.index)\n",
    "\n",
    "# Display the number of samples in each class for both train and test sets\n",
    "# Check if the number of datapoints in remaining_df + test_df equals length of original dataframe\n",
    "print(\"Test set class distribution:\\n\", test_df[class_label].value_counts())\n",
    "print(\"Train set class distribution:\\n\", remaining_df[class_label].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRjT5W4ScfI5"
   },
   "outputs": [],
   "source": [
    "# within test_df, \"text\" column is X and \"airline_sentiment\" column is Y\n",
    "# These will be referred to as X_test and y_test\n",
    "X_test= test_df[\"text\"]\n",
    "y_test= test_df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVpEjzFXQYk_",
    "outputId": "a2635892-a971-4e82-96f4-ce099fd06039"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 1151,  9111,  3326, 10891, 11322,  3709,  5261, 10060, 12446,  3089,\n",
       "       ...\n",
       "       11705, 13422,  2716,  3071, 13504,  4489,  8271, 11795,  7294,  8203],\n",
       "      dtype='int64', length=600)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTA1cJRcQfWC",
    "outputId": "b9fca4ad-27bb-4201-9f39-76453be9bcef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 1151,  9111,  3326, 10891, 11322,  3709,  5261, 10060, 12446,  3089,\n",
       "       ...\n",
       "       13324, 11935,  9346, 11781,  3022, 10759, 11149,  7523, 12754,   667],\n",
       "      dtype='int64', length=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_class_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2XoiZ5DQr7R",
    "outputId": "a89c28a2-2591-4395-f7f9-951de73216b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp5fluP-QuBr",
    "outputId": "4c48e3df-4d44-433f-a92e-0e1931841fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kv3u7i6JQC2X",
    "outputId": "05776ccf-8515-4484-c01f-80f24a2a961d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14040, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows of test_df and remaining_df when summed provides the number of rows of df\n",
    "remaining_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNAfYynAQC2Y"
   },
   "source": [
    "**OVERSAMPLE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoyZUW4Ir8T2",
    "outputId": "744596f7-cc9f-45a5-86e7-ed6f735968e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled DataFrame:\n",
      "airline_sentiment\n",
      "negative    8978\n",
      "neutral     8978\n",
      "positive    8978\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using resample function from sklearn.utils for oversampling\n",
    "# Refer https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html for official documentation\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Checking existance of class imbalance in remaining_df\n",
    "# If there is class imbalance, we will oversample the data\n",
    "# i.e. we will make sure that number of rows for each class = number of rows for that class with maximum number of datapoints\n",
    "class_counts = remaining_df['airline_sentiment'].value_counts()\n",
    "max_class_count = class_counts.max()  # Get the number of samples in the majority class (class with highest number of datapoints)\n",
    "\n",
    "# Separate each class into three different DataFrames for negative, neutral and positive respectively\n",
    "negative_df = remaining_df[remaining_df['airline_sentiment'] == 'negative']\n",
    "neutral_df = remaining_df[remaining_df['airline_sentiment'] == 'neutral']\n",
    "positive_df = remaining_df[remaining_df['airline_sentiment'] == 'positive']\n",
    "\n",
    "# Oversampling the minority classes to match the number of samples in the majority class\n",
    "# We are oversampling the negative_df and neutral_df as they are the minority classes\n",
    "neutral_df_oversampled = resample(neutral_df,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=max_class_count,    # to match the number of majority samples\n",
    "                                    random_state=42)  # reproducible results with a fixed random_state\n",
    "\n",
    "positive_df_oversampled = resample(positive_df,\n",
    "                                   replace=True,     # sample with replacement\n",
    "                                   n_samples=max_class_count,    # to match the number of majority samples\n",
    "                                   random_state=42)  # reproducible results with a fixed random_state\n",
    "\n",
    "\n",
    "# negative_df, neutral_df_oversampled and positive_df_oversampled constitute the oversampled dataframes\n",
    "# Let's concatencate them to form our complete oversampled_df\n",
    "oversampled_df = pd.concat([negative_df, neutral_df_oversampled, positive_df_oversampled])\n",
    "\n",
    "# Let's shuffle the oversampled_df dataFrame so that the order of elements does not affect any sampling choices or training process\n",
    "# Also making sure the index is reset when shuffling\n",
    "# Refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "oversampled_df = oversampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the value counts to verify the balancing\n",
    "print(\"Oversampled DataFrame:\")\n",
    "print(oversampled_df['airline_sentiment'].value_counts())\n",
    "# 8978 datapoints per class (note that it matches with the length of the class with the lowest number of datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Upc3-qkfQC2Y"
   },
   "outputs": [],
   "source": [
    "# Finalizing the training data (which is the oversampled data)\n",
    "train_df= oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lsT8ZybQC2Y"
   },
   "outputs": [],
   "source": [
    "# When saving the weight, we are providing a prefix for the name, for ease of locating weights from this experiment\n",
    "weights_path_prefix = 'Word2vec_OVERSAMPLED_DATA_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jAKtnap6b2u"
   },
   "source": [
    "### LSTM WORD2VEC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQMmaXGeQC2Y"
   },
   "source": [
    "**TRAINDATA TOKENIZATION AND PADDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VEAyA-W8BMZ",
    "outputId": "1b2214ac-b4ba-4265-e205-0892dfa22f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 531 ms, sys: 6.66 ms, total: 537 ms\n",
      "Wall time: 537 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's create a tokenizer with 10000 words (all those words which do not come under this 10000, will be marked <OOV> )\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "# Train data preprocessing\n",
    "# Fitting the tokenizer on the traindata (only the text column)\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "# Data pre-processing\n",
    "max_length = 200  # Maximum sequence length= 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'  # padding ensures embeddings of shorter sentences have the same length as that of the longer ones\n",
    "X_train = tokenizer.texts_to_sequences(train_df['text'])  # using the tokenizer on train_df['text']\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding=padding_type, truncating=trunc_type)  # let's truncate and pad the tokens\n",
    "\n",
    "\n",
    "# Let's encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['airline_sentiment'])\n",
    "num_classes = len(label_encoder.classes_)   # number of classes\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)   # converting the labels to categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QrKbNjQQC2Z"
   },
   "source": [
    "**TESTDATA TOKENIZATION AND PADDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQyqOj6E8Oey",
    "outputId": "beffed0b-5be7-4b33-e2e2-2dddc266b696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 6.63 ms, total: 26.6 ms\n",
      "Wall time: 24.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test data preprocessing\n",
    "# Performing the same steps of tokenizing,padding, and truncating on the test data too\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwmYGZMpQC2Z"
   },
   "source": [
    "**CLASS WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v3w1PqvQC2Z",
    "outputId": "c488f955-dd5a-4fdd-bce8-334be0be8c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 1.0, 'neutral': 1.0, 'positive': 1.0}\n",
      "{0: 1.0, 1: 1.0, 2: 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Find unique classes in train_df\n",
    "unique_classes = np.unique(train_df['airline_sentiment'])\n",
    "class_weights = {}\n",
    "# Calculate the weight for each class so that this weightage can be provided during training\n",
    "for cls in unique_classes:\n",
    "    class_weight = len(train_df['airline_sentiment']) / (len(unique_classes) * np.sum(train_df['airline_sentiment'] == cls))\n",
    "    class_weights[cls] = class_weight\n",
    "\n",
    "print(class_weights)\n",
    "# {0: 1.0, 1: 1.0, 2: 1.0} class weights are because all have equal weightage since class sizes are same for all 3 labels\n",
    "class_numbers= [0, 1, 2]\n",
    "class_weights= dict(zip(class_numbers,list(class_weights.values())))\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b30uglBbQC2Z"
   },
   "source": [
    "**WORD2VEC EMBEDDINGS and MODEL CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_7WE8cn82Yd",
    "outputId": "f53bebf0-5ae0-4ff9-fdb6-6e0d2dc44251"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 1.25 s, total: 12.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load Word2Vec embeddings\n",
    "word2vec_path = '/Users/unnimaya/Documents/Projectexperiments/AIRLINEDATASET/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "embedding_dim = 300  # Since we loaded 300 dimensional Word2Vec mbeddings\n",
    "word_index = tokenizer.word_index  # Loading word index of Word2Vec embeddings\n",
    "num_words = min(10000, len(word_index) + 1)   # Number of words same as that of our tokenizer we defined above\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))    # Each word has 300D, so size of embedding matrix will be 10000x300\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < 10000:  # if i<10000, assign embedding vector to the word from Word2Vec\n",
    "        try:\n",
    "            embedding_vector = word2vec[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        except KeyError:\n",
    "            pass  # Word not found in Word2Vec, the embedding will be np.zeros((num_words, embedding_dim))\n",
    "\n",
    "# Build Bidirectional LSTM model with pre-trained Word2Vec embeddings\n",
    "model = Sequential()\n",
    "# Create embedding for the input sequence using this first layer\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_length,\n",
    "                    weights=[embedding_matrix], trainable=False))\n",
    "# Using a series of Bidirectional LSTMs (with recurrent dropout) followed by dropout\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(128, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.5))\n",
    "# After the LSTM and dropout layers, we have two fully connected neural network layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # number of neurons in output layer= number of classes, activation function is softmax for multiclass classification problems\n",
    "\n",
    "# Using learning rate 0.001\n",
    "learning_rate = 0.001\n",
    "# Using Adam optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0) # using clipnorm to prevent exploding gradients if any\n",
    "\n",
    "# Compile the model with metric as accuracy and loss as categorical crossentropy (multiclass classification)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUtYfZG_QC2Z"
   },
   "outputs": [],
   "source": [
    "# Define the checkpoint callback- decides when to save weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath= weights_path_prefix+'_lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_{epoch:02d}.h5',  # Filepath format to include epoch number\n",
    "    save_weights_only=True,                         # Save only the model's weights\n",
    "    #save_freq=10 * (len(X_train) // 32),           # Save every 30 epochs (commented for now)\n",
    "    save_freq= 'epoch',                             # Save every epoch\n",
    "    verbose=1                                       # Print a message when saving the weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbqXpnTT882P",
    "outputId": "90bd905f-94fc-4439-c691-024839a4d2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.7359\n",
      "Epoch 1: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_01.h5\n",
      "842/842 [==============================] - 2985s 4s/step - loss: 0.6542 - accuracy: 0.7359 - val_loss: 0.5684 - val_accuracy: 0.7783\n",
      "Epoch 2/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.7907\n",
      "Epoch 2: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_02.h5\n",
      "842/842 [==============================] - 2723s 3s/step - loss: 0.5340 - accuracy: 0.7907 - val_loss: 0.5743 - val_accuracy: 0.7750\n",
      "Epoch 3/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8263\n",
      "Epoch 3: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_03.h5\n",
      "842/842 [==============================] - 2711s 3s/step - loss: 0.4465 - accuracy: 0.8263 - val_loss: 0.5750 - val_accuracy: 0.7983\n",
      "Epoch 4/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8595\n",
      "Epoch 4: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_04.h5\n",
      "842/842 [==============================] - 2683s 3s/step - loss: 0.3708 - accuracy: 0.8595 - val_loss: 0.5531 - val_accuracy: 0.7983\n",
      "Epoch 5/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.8891\n",
      "Epoch 5: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_05.h5\n",
      "842/842 [==============================] - 2735s 3s/step - loss: 0.3029 - accuracy: 0.8891 - val_loss: 0.6129 - val_accuracy: 0.7917\n",
      "Epoch 6/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.9108\n",
      "Epoch 6: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_06.h5\n",
      "842/842 [==============================] - 2776s 3s/step - loss: 0.2483 - accuracy: 0.9108 - val_loss: 0.8355 - val_accuracy: 0.7750\n",
      "Epoch 7/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9276\n",
      "Epoch 7: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_07.h5\n",
      "842/842 [==============================] - 2718s 3s/step - loss: 0.2112 - accuracy: 0.9276 - val_loss: 1.0016 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9273\n",
      "Epoch 8: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_08.h5\n",
      "842/842 [==============================] - 2426s 3s/step - loss: 0.2159 - accuracy: 0.9273 - val_loss: 0.8757 - val_accuracy: 0.7583\n",
      "Epoch 9/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9494\n",
      "Epoch 9: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_09.h5\n",
      "842/842 [==============================] - 2095s 2s/step - loss: 0.1533 - accuracy: 0.9494 - val_loss: 1.0805 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9569\n",
      "Epoch 10: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_10.h5\n",
      "842/842 [==============================] - 2121s 3s/step - loss: 0.1332 - accuracy: 0.9569 - val_loss: 1.0122 - val_accuracy: 0.7550\n",
      "Epoch 11/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9618\n",
      "Epoch 11: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_11.h5\n",
      "842/842 [==============================] - 2170s 3s/step - loss: 0.1175 - accuracy: 0.9618 - val_loss: 1.0404 - val_accuracy: 0.7617\n",
      "Epoch 12/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9649\n",
      "Epoch 12: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_12.h5\n",
      "842/842 [==============================] - 2172s 3s/step - loss: 0.1064 - accuracy: 0.9649 - val_loss: 1.0524 - val_accuracy: 0.7483\n",
      "Epoch 13/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9693\n",
      "Epoch 13: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_13.h5\n",
      "842/842 [==============================] - 2107s 3s/step - loss: 0.0940 - accuracy: 0.9693 - val_loss: 1.1764 - val_accuracy: 0.7750\n",
      "Epoch 14/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9735\n",
      "Epoch 14: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_14.h5\n",
      "842/842 [==============================] - 2080s 2s/step - loss: 0.0834 - accuracy: 0.9735 - val_loss: 1.4900 - val_accuracy: 0.7400\n",
      "Epoch 15/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9757\n",
      "Epoch 15: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_15.h5\n",
      "842/842 [==============================] - 1939s 2s/step - loss: 0.0758 - accuracy: 0.9757 - val_loss: 1.2628 - val_accuracy: 0.7583\n",
      "Epoch 16/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9781\n",
      "Epoch 16: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_16.h5\n",
      "842/842 [==============================] - 1525s 2s/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 1.3455 - val_accuracy: 0.7333\n",
      "Epoch 17/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 17: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_17.h5\n",
      "842/842 [==============================] - 1563s 2s/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 1.3830 - val_accuracy: 0.7317\n",
      "Epoch 18/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9810\n",
      "Epoch 18: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_18.h5\n",
      "842/842 [==============================] - 1609s 2s/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 1.8205 - val_accuracy: 0.7450\n",
      "Epoch 19/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9802\n",
      "Epoch 19: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_19.h5\n",
      "842/842 [==============================] - 1590s 2s/step - loss: 0.0599 - accuracy: 0.9802 - val_loss: 1.4743 - val_accuracy: 0.7533\n",
      "Epoch 20/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9705\n",
      "Epoch 20: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_20.h5\n",
      "842/842 [==============================] - 1590s 2s/step - loss: 0.0929 - accuracy: 0.9705 - val_loss: 0.8054 - val_accuracy: 0.7750\n",
      "Epoch 21/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9805\n",
      "Epoch 21: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_21.h5\n",
      "842/842 [==============================] - 1577s 2s/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 1.5088 - val_accuracy: 0.7483\n",
      "Epoch 22/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9848\n",
      "Epoch 22: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_22.h5\n",
      "842/842 [==============================] - 1592s 2s/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 1.6624 - val_accuracy: 0.7450\n",
      "Epoch 23/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9850\n",
      "Epoch 23: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_23.h5\n",
      "842/842 [==============================] - 1603s 2s/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 1.7573 - val_accuracy: 0.7517\n",
      "Epoch 24/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9857\n",
      "Epoch 24: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_24.h5\n",
      "842/842 [==============================] - 1562s 2s/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 1.4054 - val_accuracy: 0.7767\n",
      "Epoch 25/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9872\n",
      "Epoch 25: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_25.h5\n",
      "842/842 [==============================] - 1567s 2s/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 1.6096 - val_accuracy: 0.7583\n",
      "Epoch 26/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9859\n",
      "Epoch 26: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_26.h5\n",
      "842/842 [==============================] - 1587s 2s/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 1.8110 - val_accuracy: 0.7583\n",
      "Epoch 27/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9872\n",
      "Epoch 27: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_27.h5\n",
      "842/842 [==============================] - 1564s 2s/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 1.5339 - val_accuracy: 0.7450\n",
      "Epoch 28/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9867\n",
      "Epoch 28: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_28.h5\n",
      "842/842 [==============================] - 1549s 2s/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 1.6561 - val_accuracy: 0.7433\n",
      "Epoch 29/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9874\n",
      "Epoch 29: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_29.h5\n",
      "842/842 [==============================] - 1568s 2s/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 1.6581 - val_accuracy: 0.7633\n",
      "Epoch 30/30\n",
      "842/842 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9888\n",
      "Epoch 30: saving model to Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_30.h5\n",
      "842/842 [==============================] - 1570s 2s/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 1.9503 - val_accuracy: 0.7317\n",
      "CPU times: user 17h 12min 19s, sys: 6h 54min 54s, total: 1d 7min 14s\n",
      "Wall time: 16h 40min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRAINING THE MODEL\n",
    "# We supply test data as validation data to observe the model performance after each epoch\n",
    "# 30 iterations (epochs)\n",
    "# Uses class weight balancing based on class imbalance in data (no class imbalance here for oversampling)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=32, callbacks=[checkpoint], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw69vhVpQC2a",
    "outputId": "c6d031a9-baae-4588-9dcb-e086072b9e34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# load and compile a saved weight\n",
    "model.load_weights('Word2vec_OVERSAMPLED_DATA__lstm_weights_trainableFalse_lr0.001_recdropouts0.2_gradientclip1_classweights_epoch_04.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmYpAQLx9FJt",
    "outputId": "fe69471b-9c03-450d-839e-96e4a11229b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 272ms/step - loss: 0.5531 - accuracy: 0.7983\n",
      "Test Accuracy: 0.7983333468437195\n",
      "CPU times: user 9.65 s, sys: 3.58 s, total: 13.2 s\n",
      "Wall time: 6.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the loaded weights and evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtzgGzguQC2b",
    "outputId": "3c6bb99c-d2b5-4a66-bea7-7c327e362ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 286ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming X_test is your test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Get the predicted class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yER-QfBLQC2b",
    "outputId": "3b41c1da-31d5-404c-a1a4-ed65b5b03c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Precision = 0.8000, Recall = 0.8200\n",
      "Class 1: Precision = 0.7784, Recall = 0.7550\n",
      "Class 2: Precision = 0.8159, Recall = 0.8200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming conf_matrix is the confusion matrix\n",
    "TP = np.diag(conf_matrix)\n",
    "FP = np.sum(conf_matrix, axis=0) - TP\n",
    "FN = np.sum(conf_matrix, axis=1) - TP\n",
    "\n",
    "# Avoid division by zero\n",
    "precision = np.divide(TP, (TP + FP), where=(TP + FP) != 0)\n",
    "recall = np.divide(TP, (TP + FN), where=(TP + FN) != 0)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}: Precision = {precision[i]:.4f}, Recall = {recall[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
